{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNrd8lg0aEFn0mOeyrQ9Mzw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RobinHamers/mombasa_solutions/blob/main/get_data.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# Imports\n",
        "\n"
      ],
      "metadata": {
        "id": "rtPY8KSrAGZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q -U geopandas contextily h3pandas shapely"
      ],
      "metadata": {
        "id": "E2KKAnewC1JU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7pJQCwl_m-g"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import geopandas as gpd\n",
        "import sys\n",
        "from functools import reduce\n",
        "import contextily as ctx\n",
        "import numpy as np\n",
        "import h3pandas"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DB_PTH_DCT = {\n",
        "\n",
        "    'metrics': 'weo-data_dashboard_Heat-Risk-.zip',\n",
        "    'medical_care': 'weo-data_dashboard_medical_care.geojson',\n",
        "    'medical_care': 'weo-data_dashboard_medical_care.geojson',\n",
        "}\n",
        "\n",
        "INDEX = column_to_merge_on = 'h3'"
      ],
      "metadata": {
        "id": "-0s1R-2mAyo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collapse_duplicates(df, index_col):\n",
        "    def collapse_strings(series):\n",
        "        if series.dtype == object:\n",
        "            values = series.dropna().astype(str)\n",
        "            if values.empty:\n",
        "                return np.nan\n",
        "            seen = set()\n",
        "            unique_values = []\n",
        "            for v in values:\n",
        "                if v and v not in seen:\n",
        "                    unique_values.append(v)\n",
        "                    seen.add(v)\n",
        "            return ', '.join(unique_values)\n",
        "        else:\n",
        "            return series.dropna().iloc[0] if series.notna().any() else pd.NA\n",
        "\n",
        "    collapsed_df = df.groupby(index_col).agg(collapse_strings).reset_index()\n",
        "    return collapsed_df\n",
        "\n",
        "def get_data(data_dir=\"./\", db_pth_dct=DB_PTH_DCT, index=INDEX):\n",
        "\n",
        "    db_gdfs = {}\n",
        "\n",
        "    for key, filename in db_pth_dct.items():\n",
        "        ext = os.path.splitext(filename)[1].lower()\n",
        "        path = os.path.join(data_dir, filename)\n",
        "        if ext in [\".csv\"]:\n",
        "            df = pd.read_csv(path)\n",
        "            db_gdfs[key] = df\n",
        "        elif ext in [\".geojson\", \".gpkg\", \".zip\"]:\n",
        "            try:\n",
        "                gdf = gpd.read_file(path)\n",
        "\n",
        "                if gdf.geometry.name != 'geometry':\n",
        "                    raise ValueError(f\"GeoDataFrame {gdf.name} does not have a 'geometry' column.\")\n",
        "                if gdf.crs is None:\n",
        "                    raise ValueError(f\"GeoDataFrame {gdf.name} does not have a CRS defined.\")\n",
        "\n",
        "                if gdf.crs is not None and gdf.crs.to_string() != \"EPSG:4326\":\n",
        "                    gdf = gdf.to_crs(\"EPSG:4326\")\n",
        "\n",
        "                if key != 'comments':\n",
        "                    gdf = gdf.rename(columns={'name': key})\n",
        "                elif key == 'comments':\n",
        "                    gdf = gdf.rename(columns={'text': key})\n",
        "\n",
        "                # Handle different geometry types for H3 assignment\n",
        "                if gdf.geometry.iloc[0].geom_type == \"Point\":\n",
        "                    # For Point geometries, assign H3 index directly\n",
        "                    gdf = gdf.h3.geo_to_h3(resolution=10, set_index=False)\n",
        "                elif gdf.geometry.iloc[0].geom_type == \"MultiPoint\":\n",
        "                    # For MultiPoint geometries, calculate centroid and assign H3 index\n",
        "                    gdf = gdf.explode(ignore_index=True)\n",
        "                    gdf = gdf.h3.geo_to_h3(resolution=10, set_index=False)\n",
        "                elif gdf.geometry.iloc[0].geom_type == \"Polygon\":\n",
        "                    gdf = gdf.h3.polyfill(10+4, explode=True).set_index('h3_polyfill').h3.h3_to_parent_aggregate(10, operation = {'emergency_assemble_areas': 'first',})  # Take the first value in each group# Add other columns as needed, e.g., 'count': 'sum'\n",
        "                    gdf = gdf.reset_index()\n",
        "                else:\n",
        "                    print(f\"Unsupported geometry type {gdf.geometry.iloc[0].geom_type} for {key} in {filename}. Skipping H3 assignment.\", file=sys.stderr)\n",
        "\n",
        "                gdf['h3_int'] = gdf['h3'].apply(lambda x: int(x, 16) if pd.notna(x) else None)\n",
        "                db_gdfs[key] = gdf\n",
        "\n",
        "            except Exception as e:\n",
        "                db_gdfs[key] = None\n",
        "                print(f\"Error with {key} DB, {filename}: {e}\", file=sys.stderr)\n",
        "        else:\n",
        "            db_gdfs[key] = None\n",
        "\n",
        "\n",
        "\n",
        "    # Merge all DataFrames in db_gdfs on the 'INDEX' column\n",
        "    merged_gdf = reduce(lambda left, right: pd.merge(left, right, on=INDEX, how='outer', suffixes=('', '_dup')),  [df for df in db_gdfs.values() if isinstance(df, pd.DataFrame) and INDEX in df.columns])\n",
        "\n",
        "\n",
        "\n",
        "    #Filter the polygons that have a special feature, e.g., 'densely_populated_at_risk_people'\n",
        "    # Get all keys except 'metrics'\n",
        "    non_metrics_keys = [k for k in db_gdfs.keys() if k != 'metrics']\n",
        "    # Only keep columns that exist in merged_gdf\n",
        "    cols_to_check = [k for k in non_metrics_keys if k in merged_gdf.columns]\n",
        "\n",
        "    merged_gdf.to_csv(\"df_export.csv\", index=False)\n",
        "\n",
        "\n",
        "    for key, gdf in db_gdfs.items():\n",
        "        if gdf is not None:\n",
        "            print(f\"{key} unique polygons on total rows in DB: {gdf[INDEX].nunique()}/{len(gdf)}.\")\n",
        "        else:\n",
        "            print(f\"{key} DB is None or empty.\")\n",
        "\n",
        "    return merged_gdf.head()\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    head = get_data(data_dir=\"/content/\")\n",
        "    print(\"Head of the output = \")\n",
        "    print(head)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wIrXiGlzA7Ih",
        "outputId": "0b2bb597-0540-4999-f30c-ee279c952ab9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 54)\n",
            "number of unique h3 indices: 1\n",
            "Filtered DataFrame shape: (171805, 54)\n",
            "Added 1 missing rows from pois_df to selected_rows.\n",
            "metrics unique polygons on total rows in DB: 315603/315603.\n",
            "medical_care unique polygons on total rows in DB: 1/1.\n",
            "Path of the output =    felt:feature  felt:has_geometry       felt:h3_index                  h3  \\\n",
            "0        237694               True  647365069018628096  624847070881808383   \n",
            "1        237921               True  647365069043466240  624847070906646527   \n",
            "2         15877               True  647365069046939648  624847070910119935   \n",
            "3         15884               True  647365069047398400  624847070910578687   \n",
            "4        237973               True  647365069047955456  624847070911135743   \n",
            "\n",
            "   flood_risk  tree_count_sum  fire_risk_202501  fire_risk_202502  \\\n",
            "0         1.0             6.0               1.0               1.0   \n",
            "1         2.0             8.0               1.0               1.0   \n",
            "2         1.0             2.0               1.0               1.0   \n",
            "3         2.0             1.0               1.0               1.0   \n",
            "4         2.0            14.0               1.0               1.0   \n",
            "\n",
            "  fire_risk_seq  heat_risk  ...  felt:locked  felt:ordering  felt:parentId  \\\n",
            "0           1,1        1.0  ...          NaN            NaN            NaN   \n",
            "1           1,1        1.0  ...          NaN            NaN            NaN   \n",
            "2           1,1        1.0  ...          NaN            NaN            NaN   \n",
            "3           1,1        2.0  ...          NaN            NaN            NaN   \n",
            "4           1,1        1.0  ...          NaN            NaN            NaN   \n",
            "\n",
            "   felt:radiusDisplayAngle  felt:symbol  felt:type  felt:widthScale  place  \\\n",
            "0                      NaN          NaN        NaN              NaN    NaN   \n",
            "1                      NaN          NaN        NaN              NaN    NaN   \n",
            "2                      NaN          NaN        NaN              NaN    NaN   \n",
            "3                      NaN          NaN        NaN              NaN    NaN   \n",
            "4                      NaN          NaN        NaN              NaN    NaN   \n",
            "\n",
            "   geometry_dup  h3_10_int_dup  \n",
            "0          None            NaN  \n",
            "1          None            NaN  \n",
            "2          None            NaN  \n",
            "3          None            NaN  \n",
            "4          None            NaN  \n",
            "\n",
            "[5 rows x 54 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Ml3jhaoDDFTq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}